<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A/B Testing Framework - Vasanth Panuganti</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        .project-detail-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 100px 20px 50px;
        }

        .back-button {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
            margin-bottom: 30px;
            transition: transform 0.3s ease;
        }

        .back-button:hover {
            transform: translateX(-5px);
        }

        .project-hero {
            margin-bottom: 60px;
        }

        .project-hero h1 {
            font-size: 3rem;
            margin-bottom: 20px;
            color: var(--text-primary);
        }

        .project-meta {
            display: flex;
            gap: 30px;
            margin-bottom: 30px;
            flex-wrap: wrap;
        }

        .meta-item {
            display: flex;
            flex-direction: column;
        }

        .meta-label {
            font-size: 0.875rem;
            color: var(--text-secondary);
            margin-bottom: 5px;
        }

        .meta-value {
            font-weight: 600;
            color: var(--text-primary);
        }

        .project-tech-stack {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
            margin-top: 20px;
        }

        .tech-pill {
            padding: 8px 16px;
            background: var(--primary-color);
            color: white;
            border-radius: 20px;
            font-size: 0.875rem;
        }

        .project-section {
            margin-bottom: 50px;
        }

        .project-section h2 {
            font-size: 2rem;
            margin-bottom: 20px;
            color: var(--text-primary);
        }

        .project-section h3 {
            font-size: 1.5rem;
            margin-top: 30px;
            margin-bottom: 15px;
            color: var(--text-primary);
        }

        .project-section p {
            line-height: 1.8;
            color: var(--text-secondary);
            margin-bottom: 15px;
        }

        .project-section ul {
            list-style: none;
            padding-left: 0;
        }

        .project-section ul li {
            padding: 10px 0;
            padding-left: 25px;
            position: relative;
            line-height: 1.8;
            color: var(--text-secondary);
        }

        .project-section ul li:before {
            content: "‚Üí";
            position: absolute;
            left: 0;
            color: var(--primary-color);
            font-weight: bold;
        }

        .highlight-box {
            background: rgba(59, 130, 246, 0.1);
            border-left: 4px solid var(--primary-color);
            padding: 20px;
            margin: 30px 0;
            border-radius: 4px;
        }

        .highlight-box h4 {
            color: var(--primary-color);
            margin-bottom: 10px;
        }

        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }

        .metric-card {
            background: var(--card-bg);
            padding: 25px;
            border-radius: 8px;
            text-align: center;
            border: 1px solid var(--border-color);
        }

        .metric-value {
            font-size: 2.5rem;
            font-weight: 700;
            color: var(--primary-color);
            margin-bottom: 10px;
        }

        .metric-label {
            color: var(--text-secondary);
            font-size: 0.875rem;
        }

        @media (max-width: 768px) {
            .project-hero h1 {
                font-size: 2rem;
            }

            .project-section h2 {
                font-size: 1.5rem;
            }
        }
    </style>
</head>
<body>
    <nav class="navbar" id="navbar">
        <div class="nav-container">
            <a href="index.html" class="logo">VP</a>
            <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                <span class="theme-icon">üåô</span>
            </button>
        </div>
    </nav>

    <div class="project-detail-container">
        <a href="index.html#projects" class="back-button">‚Üê Back to Projects</a>

        <div class="project-hero">
            <h1>A/B Testing Framework</h1>
            <div class="project-meta">
                <div class="meta-item">
                    <span class="meta-label">Role</span>
                    <span class="meta-value">Experimentation Platform Lead</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Duration</span>
                    <span class="meta-value">7 months</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Team Size</span>
                    <span class="meta-value">5 members</span>
                </div>
            </div>
            <div class="project-tech-stack">
                <span class="tech-pill">Python</span>
                <span class="tech-pill">Django</span>
                <span class="tech-pill">PostgreSQL</span>
                <span class="tech-pill">Redis</span>
                <span class="tech-pill">React</span>
                <span class="tech-pill">Docker</span>
            </div>
        </div>

        <div class="project-section">
            <h2>Project Overview</h2>
            <p>
                Built a comprehensive A/B testing platform from the ground up that enabled the organization to run rigorous, statistically sound experiments at scale. The framework democratized experimentation across the company, allowing product teams to test hypotheses quickly and make data-driven decisions with confidence.
            </p>
        </div>

        <div class="project-section">
            <h2>The Challenge</h2>
            <p>
                The company was making product decisions based on intuition and HiPPO (Highest Paid Person's Opinion) rather than data:
            </p>
            <ul>
                <li>No systematic way to validate product changes before full rollout</li>
                <li>Previous experiments lacked statistical rigor and proper controls</li>
                <li>Manual experiment tracking in spreadsheets prone to errors</li>
                <li>No infrastructure for traffic splitting and variant assignment</li>
                <li>Results analysis took weeks, slowing iteration cycles</li>
                <li>Conflicting experiments interfering with each other</li>
                <li>Engineering overhead required for each new experiment</li>
                <li>Limited ability to run experiments on mobile apps and backend systems</li>
            </ul>
            <p>
                The organization needed a robust, self-service platform to embed experimentation into the product development process.
            </p>
        </div>

        <div class="project-section">
            <h2>Solution & Implementation</h2>

            <h3>1. Core Experimentation Engine</h3>
            <p>
                Built the foundational infrastructure for experiment execution:
            </p>
            <ul>
                <li>Consistent hashing algorithm for stable user-to-variant assignment</li>
                <li>Traffic allocation system supporting arbitrary split percentages</li>
                <li>Holdout groups for long-term impact measurement</li>
                <li>Ramp-up capability to gradually increase treatment exposure</li>
                <li>Kill switch for immediate experiment termination</li>
                <li>Experiment namespace management to prevent collisions</li>
                <li>Support for multi-variate testing (MVT) beyond simple A/B</li>
            </ul>

            <h3>2. Statistical Analysis Engine</h3>
            <p>
                Implemented rigorous statistical methods for result interpretation:
            </p>
            <ul>
                <li>Bayesian and Frequentist statistical approaches</li>
                <li>Sequential testing to enable early stopping</li>
                <li>Multiple testing correction (Bonferroni, FDR)</li>
                <li>Sample size calculation and power analysis</li>
                <li>Statistical significance testing with confidence intervals</li>
                <li>Automated detection of Simpson's paradox</li>
                <li>Segmented analysis for heterogeneous treatment effects</li>
            </ul>

            <h3>3. Self-Service Web Interface</h3>
            <p>
                Created an intuitive UI for non-technical users:
            </p>
            <ul>
                <li>Experiment creation wizard with templates</li>
                <li>Visual experiment designer with drag-and-drop</li>
                <li>Real-time results dashboard with customizable metrics</li>
                <li>Experiment calendar showing all active and planned tests</li>
                <li>Automated alerts for statistical significance and anomalies</li>
                <li>Experiment documentation and hypothesis tracking</li>
                <li>Collaboration features for team-based experimentation</li>
            </ul>

            <h3>4. SDK & Integration Layer</h3>
            <p>
                Developed easy integration for web, mobile, and backend:
            </p>
            <ul>
                <li>Lightweight JavaScript SDK for web applications</li>
                <li>Native SDKs for iOS (Swift) and Android (Kotlin)</li>
                <li>Python library for backend experimentation</li>
                <li>RESTful API for custom integrations</li>
                <li>Client-side and server-side evaluation options</li>
                <li>Local caching for low-latency variant assignment</li>
                <li>Automatic event tracking for metrics</li>
            </ul>
        </div>

        <div class="highlight-box">
            <h4>Key Innovation</h4>
            <p>
                Developed an "Intelligent Experiment Scheduler" that automatically manages experiment conflicts, recommends optimal sample sizes, and suggests experiment duration based on historical traffic patterns and metric variance. This reduced setup time from hours to minutes.
            </p>
        </div>

        <div class="project-section">
            <h2>Technical Architecture</h2>

            <h3>System Components</h3>
            <p>
                Microservices architecture for scalability and reliability:
            </p>
            <ul>
                <li><strong>Assignment Service:</strong> Redis-backed service for low-latency variant assignment (<5ms)</li>
                <li><strong>Event Collection:</strong> Kafka pipeline for high-throughput metric tracking</li>
                <li><strong>Analysis Service:</strong> Python service for statistical computations</li>
                <li><strong>Admin Portal:</strong> React-based web application for experiment management</li>
                <li><strong>Data Warehouse:</strong> PostgreSQL for experiment metadata and results storage</li>
                <li><strong>Reporting Service:</strong> Aggregates metrics and generates insights</li>
            </ul>

            <h3>Data Pipeline</h3>
            <p>
                Real-time and batch processing for comprehensive analysis:
            </p>
            <ul>
                <li>Kafka for streaming event ingestion (100K+ events/second)</li>
                <li>Real-time aggregation for live experiment dashboards</li>
                <li>Batch processing for complex statistical analysis</li>
                <li>Data validation and quality checks at ingestion</li>
                <li>Retention policies for historical experiment data</li>
            </ul>

            <h3>Infrastructure</h3>
            <p>
                Cloud-native deployment for reliability and scale:
            </p>
            <ul>
                <li>Kubernetes orchestration with auto-scaling</li>
                <li>Docker containers for consistent deployments</li>
                <li>Redis Cluster for high-availability caching</li>
                <li>PostgreSQL with replication for data durability</li>
                <li>Load balancers for traffic distribution</li>
                <li>Monitoring with Prometheus and Grafana</li>
            </ul>
        </div>

        <div class="project-section">
            <h2>Key Features</h2>

            <h3>Experiment Management</h3>
            <p>
                Comprehensive tools for the experiment lifecycle:
            </p>
            <ul>
                <li>Hypothesis documentation and success criteria definition</li>
                <li>Target audience segmentation (geography, device, user attributes)</li>
                <li>Scheduled start and automatic end dates</li>
                <li>Gradual rollout capability (1% ‚Üí 10% ‚Üí 50% ‚Üí 100%)</li>
                <li>Experiment cloning for iteration testing</li>
                <li>Version control for experiment configurations</li>
            </ul>

            <h3>Metrics & Analysis</h3>
            <p>
                Flexible metric definition and analysis:
            </p>
            <ul>
                <li>Custom metric builder with aggregation functions</li>
                <li>Primary and guardrail metrics configuration</li>
                <li>Funnel analysis for conversion tracking</li>
                <li>Retention cohort analysis</li>
                <li>Revenue and business impact estimation</li>
                <li>Segment breakdown (mobile vs. desktop, new vs. returning, etc.)</li>
            </ul>

            <h3>Quality Safeguards</h3>
            <p>
                Built-in protection against common pitfalls:
            </p>
            <ul>
                <li>Sample ratio mismatch detection (alert if traffic split is skewed)</li>
                <li>Novelty effect monitoring and adjustment</li>
                <li>Automated detection of data quality issues</li>
                <li>Carryover effect analysis for sequential experiments</li>
                <li>Peer review workflow before launch</li>
            </ul>

            <h3>Reporting & Documentation</h3>
            <p>
                Comprehensive knowledge management:
            </p>
            <ul>
                <li>Automated experiment summaries with key findings</li>
                <li>Visual reports exportable to PDF and PowerPoint</li>
                <li>Experiment repository with search and filters</li>
                <li>Learning library cataloging insights from past experiments</li>
                <li>Integration with Confluence for documentation</li>
            </ul>
        </div>

        <div class="project-section">
            <h2>Results & Impact</h2>
            <div class="metrics-grid">
                <div class="metric-card">
                    <div class="metric-value">250+</div>
                    <div class="metric-label">Experiments Run in Year 1</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">5x</div>
                    <div class="metric-label">Increase in Experiment Velocity</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">$4.2M</div>
                    <div class="metric-label">Incremental Revenue from Wins</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">87%</div>
                    <div class="metric-label">Adoption Rate Across Teams</div>
                </div>
            </div>

            <h3>Business Impact</h3>
            <ul>
                <li>Enabled data-driven culture with 250+ experiments in first year</li>
                <li>Prevented 15+ feature launches that tested negatively, saving development costs</li>
                <li>Won experiments contributed $4.2M in incremental annual revenue</li>
                <li>Reduced time from idea to validated learning from 6 weeks to 2 weeks</li>
                <li>Increased product team confidence in decisions by 60% (survey data)</li>
                <li>Avoided 8 major product mistakes through early testing</li>
            </ul>

            <h3>Organizational Impact</h3>
            <ul>
                <li>87% of product teams actively running experiments</li>
                <li>Shifted decision-making from opinions to evidence</li>
                <li>Created shared language around experimentation and statistics</li>
                <li>Reduced engineering time spent on experiment infrastructure by 80%</li>
                <li>Built institutional knowledge through experiment repository</li>
            </ul>
        </div>

        <div class="project-section">
            <h2>Notable Experiments</h2>

            <h3>Checkout Flow Redesign</h3>
            <p>
                Tested simplified checkout process:
            </p>
            <ul>
                <li><strong>Hypothesis:</strong> Reducing checkout steps from 4 to 2 will increase conversion</li>
                <li><strong>Result:</strong> 23% increase in checkout completion rate</li>
                <li><strong>Impact:</strong> $1.8M annual revenue increase</li>
                <li><strong>Surprise finding:</strong> Benefit was 2x larger on mobile than desktop</li>
            </ul>

            <h3>Pricing Page Experiment</h3>
            <p>
                Tested different pricing presentation strategies:
            </p>
            <ul>
                <li><strong>Hypothesis:</strong> Annual pricing emphasis will increase LTV</li>
                <li><strong>Result:</strong> 18% increase in annual plan selection</li>
                <li><strong>Impact:</strong> Improved cash flow and reduced churn</li>
                <li><strong>Learning:</strong> Required 3-month runtime to measure retention impact</li>
            </ul>

            <h3>Notification Frequency Test</h3>
            <p>
                Optimized push notification cadence:
            </p>
            <ul>
                <li><strong>Hypothesis:</strong> More frequent notifications will increase engagement</li>
                <li><strong>Result:</strong> REJECTED - actually decreased engagement by 12%</li>
                <li><strong>Impact:</strong> Prevented rollout of harmful feature</li>
                <li><strong>Learning:</strong> Optimal frequency is 3-4 notifications per week</li>
            </ul>
        </div>

        <div class="project-section">
            <h2>Challenges & Learnings</h2>

            <h3>Statistical Education</h3>
            <p>
                Bridging the knowledge gap across the organization:
            </p>
            <ul>
                <li>Created "Experimentation 101" training program for all PMs</li>
                <li>Built intuitive visualizations to explain statistical concepts</li>
                <li>Established "office hours" for experiment design consultation</li>
                <li>Developed experimentation playbook with best practices</li>
            </ul>

            <h3>Balancing Speed and Rigor</h3>
            <p>
                Learned when to be flexible vs. strict on methodology:
            </p>
            <ul>
                <li>Fast-track approvals for low-risk experiments</li>
                <li>Strict review for experiments affecting revenue or core flows</li>
                <li>Standardized templates for common experiment types</li>
                <li>Automated quality checks to catch issues early</li>
            </ul>

            <h3>Handling Edge Cases</h3>
            <p>
                Addressed complex scenarios:
            </p>
            <ul>
                <li>Network effects where user behavior affects others</li>
                <li>Delayed conversion events requiring long experiment durations</li>
                <li>Seasonal variation requiring time-matched controls</li>
                <li>Cross-platform experiments (web + mobile + email)</li>
            </ul>
        </div>

        <div class="highlight-box">
            <h4>Key Takeaway</h4>
            <p>
                Building the technical platform is only 30% of the challenge. The real work is cultural: teaching teams to think in hypotheses, embrace failure as learning, and trust data over intuition. Invest heavily in education and evangelism alongside platform development.
            </p>
        </div>

        <div class="project-section">
            <h2>Best Practices Established</h2>

            <h3>Experiment Design Principles</h3>
            <ul>
                <li>Start with a clear hypothesis and success criteria</li>
                <li>Define primary metric before looking at data</li>
                <li>Always run with proper control group (no A/A testing shortcuts)</li>
                <li>Calculate required sample size upfront</li>
                <li>Set experiment duration based on power analysis, not calendar</li>
                <li>Monitor guardrail metrics to prevent unintended consequences</li>
            </ul>

            <h3>Analysis Guidelines</h3>
            <ul>
                <li>Don't peek at results until reaching target sample size</li>
                <li>Look at segmented results to understand heterogeneous effects</li>
                <li>Check for novelty effects with cohort analysis</li>
                <li>Always investigate surprising results before declaring victory</li>
                <li>Document learnings even from "failed" experiments</li>
            </ul>
        </div>

        <div class="project-section">
            <h2>Future Enhancements</h2>
            <ul>
                <li>Machine learning for automated experiment analysis and insights</li>
                <li>Causal inference methods for observational studies</li>
                <li>Multi-armed bandit optimization for dynamic allocation</li>
                <li>Integration with feature flag systems</li>
                <li>Real-time collaboration features (Google Docs-style)</li>
                <li>Automated experiment ideation based on user behavior</li>
                <li>Cross-company experiment meta-analysis</li>
                <li>Support for switchback experiments (time-based randomization)</li>
            </ul>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>
